import numpy as np
import heapq

class Hierarchical_A_Star:
    def __init__(self, env):
        self.env = env
        self.current_goal = np.full((env.size, env.size), -1)  
        self.solve_states = []
                           
    def create_goal_array_by_row(self, n: int, row: int) -> list[np.ndarray]:
        """
        Generates multiple goal states for an n x n sliding puzzle by modifying a specific row 
        and allowing variations of the empty tile (0) in the remaining unsolved rows.

        The function updates `self.current_goal` by setting the specified row (`row - 1`) 
        to a sequential number sequence. It then creates multiple variations of the goal state 
        by placing the empty tile (`0`) in different locations in the remaining rows.

        Parameters:
        -----------
        n : int
            The size of the sliding puzzle (n x n grid).
        row : int
            The row (1-based index) that should be finalized in the goal state.

        Returns:
        --------
        list[np.ndarray]
            A list of `n x n` NumPy arrays representing possible goal states.
            If `row == n`, only one goal state is returned with the last tile set to 0.
            Otherwise, multiple goal states are generated by placing the empty tile in different 
            positions in the unsolved rows.

        Example:
        --------
        Suppose `self.current_goal` is a `4x4` grid and `row = 2`:

        ```
        [[ 1  2  3  4]
        [ 5  6  7  8]
        [ 9 10 11 12]
        [13 14 15  0]]
        ```

        The function will first ensure that row 2 is `[5, 6, 7, 8]`. Then it will return 
        multiple goal states where the empty tile (`0`) is placed at different positions 
        in rows 3 and 4, like:

        ```
        [[ 1  2  3  4]     [[ 1  2  3  4]
        [ 5  6  7  8]      [ 5  6  7  8]
        [ 9 10 11  0]      [ 9 10 11 12]
        [13 14 15 12]]     [13 14  0 15]]
        ```

        Notes:
        ------
        - If `row == n`, the function only sets the last tile in the bottom-right to `0` and returns.
        - This function is useful for defining goal states at different levels of puzzle solving.
        """
        arr = self.current_goal
        start_num = (row - 1) * n + 1
        arr[row - 1] = np.arange(start_num, start_num + n)
        
        goals = []

        if n == row:
            arr[-1, -1] = 0
            goals.append(arr)
            return goals
            
        for i in range(row, n):      # unsolved row indices
            for j in range(n):       # all columns in that row
                new_goal = arr.copy()
                new_goal[i, j] = 0
                goals.append(new_goal)
        
        return goals
    
    def mask_by_cumulative_rows(self, arr: list[list[int]], row: int) -> np.ndarray:
        """
        Masks an input `n x n` puzzle grid by revealing only the smallest `row * n` elements 
        in a row-wise cumulative fashion, while replacing other elements with `-1`.

        The function sorts all non-zero elements, selects the smallest `row * n` values, and 
        creates a masked version of the grid where only those selected values and zeros remain 
        visible.

        Parameters:
        -----------
        arr : list[list[int]]
            The `n x n` grid of integers representing a puzzle state.
        row : int
            The number of rows to cumulatively reveal based on the smallest values.

        Returns:
        --------
        np.ndarray
            A masked version of the input grid, where only `row * n` smallest elements 
            (plus any zeros) are retained, and all other elements are set to `-1`.

        Example:
        --------
        Input:
        ```
        arr = [[8, 3, 7, 4],
            [2, 1, 6, 5],
            [12, 11, 9, 10],
            [16, 15, 14, 13]]
        row = 2
        ```

        Sorted non-zero values:
        ```
        [1, 2, 3, 4, 5, 6, 7, 8]
        ```

        Output:
        ```
        [[-1,  3, -1,  4]
        [ 2,  1, -1,  5]
        [-1, -1, -1, -1]
        [-1, -1, -1, -1]]
        ```

        Notes:
        ------
        - `self.env.size` determines the grid size (`n`).
        - The function ensures that `0` values remain unchanged.
        - Useful for progressively revealing parts of a solved puzzle while maintaining hidden information.
        """
        arr = np.array(arr).reshape(self.env.size, self.env.size)
        masked = np.full(arr.shape, -1)
        
        sorted_arr = np.sort(arr[arr != 0])
        cumulative_elements = sorted_arr[:row * arr.shape[1]]
        
        for i in range(arr.shape[0]):
            for j in range(arr.shape[1]):
                if arr[i, j] in cumulative_elements or arr[i, j] == 0:
                    masked[i, j] = arr[i, j]
        
        return masked
    
    def manhattan_distance(self, puzzle, goal_puzzle): #this one is fine
        """
        Compute the Manhattan distance between puzzle and goal_puzzle.
        Both are expected as np.array (2D).
        """
        size = self.env.size
        distance = 0
        
        puzzle_flat = puzzle.ravel()
        heuristic_goal = goal_puzzle[-1]
        goal_flat = heuristic_goal.ravel()
        
        for index, tile in enumerate(puzzle_flat):
            if tile == 0 or tile == -1:  # Ignore the blank or masked tiles
                continue
            
            # Find tile position in goal
            goal_index = np.where(goal_flat == tile)[0][0]
            
            # Convert indices to row/col
            row, col = divmod(index, size)
            goal_row, goal_col = divmod(goal_index, size)
            
            # Add Manhattan distance
            distance += abs(row - goal_row) + abs(col - goal_col)
        
        return distance

    
    def get_neighbors(self, puzzle): # I have to make sure that those dr and dc going to be needed at all. perhaps on reshaping the array?
                                        # ps: yes, they are going to be needed to re-implement the -1 -1 kind array
        '''
        new_puzzle (np.array): The 2D numpy array representing the puzzle state after making the move.
        (dr, dc) (tuple): The move made to reach that state, where:
        dr: Change in row (-1 for up, +1 for down)
        dc: Change in column (-1 for left, +1 for right)
        '''
        size = self.env.size
        neighbors = []
        
        # Find the position of the empty tile (0)
        zero_position = np.argwhere(puzzle == 0)[0]
        row, col = zero_position
        
        # Possible moves: Up, Down, Left, Right
        moves = [(-1, 0), (1, 0), (0, -1), (0, 1)]
        
        for dr, dc in moves:
            new_row, new_col = row + dr, col + dc
            if 0 <= new_row < size and 0 <= new_col < size:
                # Create a copy to modify (using np.copy)
                new_puzzle = puzzle.copy()
                # Swap the zero with the neighbor
                new_puzzle[row, col], new_puzzle[new_row, new_col] = new_puzzle[new_row, new_col], new_puzzle[row, col]
                neighbors.append((new_puzzle, (dr, dc)))
        
        return neighbors

    
    def apply_steps(self, puzzle, steps):
        """
        Applies a sequence of moves to the given puzzle state.
        
        Each move in `steps` is expected to be a tuple (state, move),
        where `move` is itself a tuple (dr, dc) indicating the direction
        to slide the blank (0). The function returns the puzzle state after
        all moves have been applied.
        
        :param puzzle: np.array representing the current puzzle state.
        :param steps: List of moves [(state, (dr, dc))] to apply.
        :return: np.array representing the updated puzzle state.
        """
        applied_puzzle = puzzle.copy()
        
        for step in steps:
            # Extract the move (dr, dc); step is assumed to be (state, move)
            _, move = step
            dr, dc = move
            
            # Find the position of the blank tile (value 0)
            zero_pos = np.argwhere(applied_puzzle == 0)[0]
            r, c = zero_pos
            
            # Compute new position for the blank tile
            new_r, new_c = r + dr, c + dc
            
            # Swap the blank with the adjacent tile
            applied_puzzle[r, c], applied_puzzle[new_r, new_c] = (
                applied_puzzle[new_r, new_c],
                applied_puzzle[r, c],
            )
        
        return applied_puzzle

    
    def solve_row_by_row(self, puzzle, goal, steps_so_far):
        """
        Solve a simplified puzzle using A* search.
        :param puzzle: np.array (Simplified puzzle)
        :param goal: List of np.array (Possible goal states)
        :return: List of moves [(state, move)]
        """
        if steps_so_far:
            puzzle = self.apply_steps(puzzle, steps_so_far)

        # print(f"Solving row for puzzle:\n{puzzle}")
        # print(f"Target goal:\n{goal}")

        path = self.a_star_search(puzzle, goal)

        if path is None:
            # print("No solution found for this row.")
            return []

        if len(path) == 0:
            # print("Already solved! No moves needed.")
            return []

        # print(f"Solved row with {len(path)} steps!")
        # for step, (state, move) in enumerate(path, 1):
            # print(f"Step {step} (Move {move}):\n{state}\n{'-' * 20}")

        return path

    def solve(self):
        puzzle = self.env.puzzle_to_solve
        n = self.env.size
        solve_steps = []
        
        if n % 2 == 1:  # If n is odd, solve row-by-row normally
            for i in range(1, n + 1):
                goal_state_n = self.create_goal_array_by_row(n, i)
                simplified_puzzle = self.mask_by_cumulative_rows(puzzle, i)
                steps = self.solve_row_by_row(simplified_puzzle, goal_state_n, solve_steps)
                solve_steps += steps
                
        else:  # If n is even, solve all but the last two rows normally
            for i in range(1, n - 1):
                goal_state_n = self.create_goal_array_by_row(n, i)
                simplified_puzzle = self.mask_by_cumulative_rows(puzzle, i)
                steps = self.solve_row_by_row(simplified_puzzle, goal_state_n, solve_steps)
                solve_steps += steps

            last_two_rows_goal = self.create_goal_state_for_last_two_rows(n)  # New function
            simplified_puzzle = self.mask_by_cumulative_rows(puzzle, n)  # Mask both rows
            steps = self.solve_row_by_row(simplified_puzzle, last_two_rows_goal, solve_steps)
            solve_steps += steps
            
        self.solve_states = solve_steps
        one_dim_solution = self.reconstruct_solution_steps()
        
        return one_dim_solution

    def create_goal_state_for_last_two_rows(self, n) -> list[np.ndarray]:
        """
        Generates the correct goal state for the last two rows to ensure parity solvability.
        """
        arr = self.current_goal.copy()
        
        # Fill in both last two rows properly
        start_num = (n - 2) * n + 1
        arr[-2] = np.arange(start_num, start_num + n)  # Fill second-last row
        arr[-1] = np.arange(start_num + n, start_num + 2 * n)  # Fill last row
        arr[-1, -1] = 0  # Ensure last tile is empty
        
        return [arr]   
 
    def a_star_search(self, start, goal):
        """
        Perform A* search from start to goal using Manhattan distance.
        :param start: np.array (start puzzle state)
        :param goal: List of np.array (goal puzzle states)
        :return: List of moves [(puzzle, move)] from start to goal
        """
        
        if any(np.array_equal(start, g) for g in goal):
            return []
        
        open_list = []
        
        goal_bytes_set = {g.tobytes() for g in goal}

        g_score = {start.tobytes(): 0}
        f_score = {start.tobytes(): self.manhattan_distance(start, goal)}

        heapq.heappush(open_list, (f_score[start.tobytes()], 0, start.tobytes(), []))

        visited = set()

        while open_list:
            _, cost, current_bytes, path = heapq.heappop(open_list)
            current_state = np.frombuffer(current_bytes, dtype=start.dtype).reshape(start.shape)

            if current_bytes in goal_bytes_set:
                return path

            if current_bytes in visited:
                continue
            visited.add(current_bytes)

            for neighbor, move in self.get_neighbors(current_state):
                neighbor_bytes = neighbor.tobytes()
                tentative_g = cost + 1

                if neighbor_bytes not in g_score or tentative_g < g_score[neighbor_bytes]:
                    g_score[neighbor_bytes] = tentative_g
                    f_score[neighbor_bytes] = tentative_g + self.manhattan_distance(neighbor, goal)
                    new_path = path + [(neighbor, move)]
                    heapq.heappush(open_list, (f_score[neighbor_bytes], tentative_g, neighbor_bytes, new_path))

        return []
    
    def reconstruct_solution_steps(self):
        """
        Reconstructs the sequence of solved steps in a 1D flattened format by applying 
        each recorded move to the initial puzzle state.

        Returns:
        --------
        list[list[int]]
            A list where each entry represents the puzzle state (flattened 1D) at each step.
        """
        if not self.solve_states:
            return []

        puzzle = self.env.puzzle_to_solve.copy()  # Start from the initial puzzle state
        puzzle = np.array(puzzle).reshape(self.env.size, self.env.size)
        reconstructed_steps = [puzzle.flatten().tolist()]  # Store the initial state as a list
        
        for step, (state, move) in enumerate(self.solve_states):
            dr, dc = move  # Extract move direction
            zero_pos = np.argwhere(puzzle == 0)[0]  # Find empty tile position
            r, c = zero_pos

            # Compute the new position for the empty tile
            new_r, new_c = r + dr, c + dc

            # Apply the move (swap)
            puzzle[r, c], puzzle[new_r, new_c] = puzzle[new_r, new_c], puzzle[r, c]

            # Store the new state as a regular Python list
            reconstructed_steps.append(puzzle.flatten().tolist())

        return reconstructed_steps


        
            
# from Puzzle_env import SlidingPuzzleEnv

# env = SlidingPuzzleEnv(size=4)
# agent = EnhancedSearch(env)

# env.generate_puzzle()
# solve_steps = agent.solve()

# print("\n===== Solution Steps =====\n")
# print(agent.env.puzzle_to_solve)

# print(solve_steps)
# for i in range(len(solve_steps)):
#     print(solve_steps[i])


# # for step, (state, move) in enumerate(solve_steps, 1):
# #     print(f"Step {step}: Move {move}\n")
# #     print(state)
# #     print("\n" + "-" * 20 + "\n")